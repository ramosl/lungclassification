{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pydicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from skimage import measure, morphology\n",
    "\n",
    "\n",
    "# Some constants \n",
    "INPUT_FOLDER = './stage2/'\n",
    "OUTPUT_FOLDER = './processed_images_stage_2/'\n",
    "\n",
    "patients = os.listdir(INPUT_FOLDER)\n",
    "\n",
    "\n",
    "labels = pd.read_csv('stage2_solution.csv')\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "patients.sort()\n",
    "print(len(patients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet. \n",
    "def load_scan(path):\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load('patient_1.npy')\n",
    "image += 350\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack all the slices to create an image of a lung\n",
    "# Convert the pixel values to Hounsfield Units (HU)\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet. \n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Resample all the slices such that the spacing between them is 1 mm x 1mm x 1mm\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every axial slice in the scan, determine the largest solid connected component \n",
    "# (the body+air around the person), and set others to 0. This fills the structures in the lungs in the mask.\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "def largest_label_volume(im, bg=-1):\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "\n",
    "    counts = counts[vals != bg]\n",
    "    vals = vals[vals != bg]\n",
    "\n",
    "    if len(counts) > 0:\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#segments out lung tissue from the rest of the CT scan\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    \n",
    "    # not actually binary, but 1 and 2. \n",
    "    # 0 is treated as background, which we do not want\n",
    "    binary_image = np.array(image > -320, dtype=np.int8)+1\n",
    "    labels = measure.label(binary_image)\n",
    "    \n",
    "    # Pick the pixel in the very corner to determine which label is air.\n",
    "    #   Improvement: Pick multiple background labels from around the patient\n",
    "    #   More resistant to \"trays\" on which the patient lays cutting the air \n",
    "    #   around the person in half\n",
    "    background_label = labels[0,0,0]\n",
    "    \n",
    "    #Fill the air around the person\n",
    "    binary_image[background_label == labels] = 2\n",
    "    \n",
    "    \n",
    "    # Method of filling the lung structures (that is superior to something like \n",
    "    # morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        # For every slice we determine the largest solid structure\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            axial_slice = axial_slice - 1\n",
    "            labeling = measure.label(axial_slice)\n",
    "            l_max = largest_label_volume(labeling, bg=0)\n",
    "            \n",
    "            if l_max is not None: #This slice contains some lung\n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "\n",
    "    \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image # Invert it, lungs are now 1\n",
    "    \n",
    "    # Remove other air pockets insided body\n",
    "    labels = measure.label(binary_image, background=0)\n",
    "    l_max = largest_label_volume(labels, bg=0)\n",
    "    if l_max is not None: # There are air pockets\n",
    "        binary_image[labels != l_max] = 0\n",
    " \n",
    "    return binary_image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the given 3d image\n",
    "# Not used for actual preprocessing except to check correctness of methods\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "def plot_3d(image, threshold=-300):\n",
    "    \n",
    "    # Position the scan upright, \n",
    "    # so the head of the patient would be at the top facing the camera\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    verts, faces, x, y = measure.marching_cubes(p, threshold) \n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n",
    "    face_color = [0.45, 0.45, 0.75]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method to zero-center images. PIXEL_Mean value is based on LUNA16 dataset, which is similar to this dataset.\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "PIXEL_MEAN = 0.25\n",
    "\n",
    "def zero_center(image):\n",
    "    image = image - PIXEL_MEAN\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method to normalize the image data since HU over +400 is uninteresting since\n",
    "#it is simply bone.\n",
    "#\n",
    "# Credit to Guido Zuidhof from the Full Preprocessing Tutorial kernal\n",
    "# from the Kaggle Data Science Bowl 2017 competition for this code snippet.\n",
    "\n",
    "MIN_BOUND = -1000.0\n",
    "MAX_BOUND = 400.0\n",
    "    \n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocess all the images for the patients in a given stage. \n",
    "for i in range(1, len(patients)):\n",
    "    \n",
    "    if patients[i] == '.DS_Store': continue;\n",
    "    print(str(i))\n",
    "    patient = load_scan(INPUT_FOLDER + patients[i])\n",
    "    patient_pixels = get_pixels_hu(patient)\n",
    "    pix_resampled, spacing = resample(patient_pixels, patient, [1,1,1])\n",
    "    segmented_lungs_fill = segment_lung_mask(pix_resampled, True)\n",
    "    \n",
    "    #comment the following line out when actually preprocessing the entire dataset.\n",
    "    #plot_3d(segmented_lungs_fill,0) \n",
    "    \n",
    "    np.save(OUTPUT_FOLDER + 'patient_' + str(i), segmented_lungs_fill)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a np vector of the true values based on patient numbers.\n",
    "# 1 = cancer; 0 = no cancer\n",
    "true_cancer_labels = np.zeros((len(patients), 1))\n",
    "\n",
    "for i in range(1, len(patients)):\n",
    "    path = OUTPUT_FOLDER + 'patient_' + str(i) + '.npy'\n",
    "    if os.path.isfile(path):\n",
    "        true_cancer_labels[i] = labels.loc[labels['id'] == patients[i]].values[0][1]\n",
    "        true_cancer_labels[i]\n",
    "        \n",
    "np.save('stage2_yTrue', true_cancer_labels)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method that performs and the normalization and zeroing of data in one function.\n",
    "#Covers all patients in a stage.\n",
    "def normalize_and_zero():\n",
    "    for i in range(0, len(patients)):\n",
    "        path = OUTPUT_FOLDER + 'patient_' + str(i) + '.npy'\n",
    "        if os.path.isfile(path):\n",
    "            image = np.load(path)\n",
    "            image = normalize(image)\n",
    "            image = zero_center(image)\n",
    "            np.save(OUTPUT_FOLDER + 'patient_' + str(i), image)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the tuple needed to pad a current sized dimension to the desired sized dimension using np.pad\n",
    "def getPadding(current, desired):\n",
    "    after = (desired - current)/2\n",
    "    before = after\n",
    "    if current %2 != 0:\n",
    "        before += 1  #arbitrarily decide to divide odd numbers to favor an extra pixel on the left.\n",
    "    return (before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pad a given image to the given sizes for each dimension.\n",
    "def padImage(image,size_x, size_y, size_z):\n",
    "    image = np.pad(image, (getPadding(image.shape[0], size_x), getPadding(image.shape[1], size_y), getPadding(image.shape[2], size_z)), mode = 'edge')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crop the center an image to a desired size. \n",
    "def crop(image, crop_size):\n",
    "    \n",
    "    start_x = image.shape[0]/2 - crop_size/2\n",
    "    end_x = image.shape[0]/2 + crop_size/2\n",
    "    start_y = image.shape[1]/2 - crop_size/2\n",
    "    end_y = image.shape[1]/2 + crop_size/2\n",
    "    start_z = image.shape[2]/2 - crop_size/2\n",
    "    end_z = image.shape[2]/2 + crop_size/2\n",
    "    process_image = image[start_x:end_x, start_y:end_y, start_z:end_z]\n",
    "    return process_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the max axis sizes to determine the padding to normalize images without resizing them. \n",
    "max_x = -1;\n",
    "max_y = -1;\n",
    "max_z = -1\n",
    "for i in range(0, len(patients)):\n",
    "        path = OUTPUT_FOLDER + 'patient_' + str(i) + '.npy'\n",
    "        if os.path.isfile(path):\n",
    "            image = np.load(path)\n",
    "            if image.shape[0] > max_x:\n",
    "                max_x = image.shape[0]\n",
    "            if image.shape[1] > max_y:\n",
    "                max_y = image.shape[1]\n",
    "            if image.shape[2] > max_z:\n",
    "                max_z = image.shape[2]\n",
    "print(\"max x is \" + str(max_x))\n",
    "print(\"max y is \" + str(max_y))\n",
    "print(\"max z is \" + str(max_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Max axis sizes found by the previous block\n",
    "x_size = 404\n",
    "y_size = 500\n",
    "z_size = 500\n",
    "\n",
    "height_width = 64     #desired height and width dimension to be used for resizing\n",
    "batch_size = 20       #Number of examples to group together in one mini_train/mini_test file\n",
    "\n",
    "batch_num = 0    #used to keep track of which batch we are on\n",
    "count = 0        #used to keep track of which example in a given batch we are in.\n",
    "\n",
    "#create training set of size 100\n",
    "x_train = np.zeros((batch_size, height_width,height_width,z_size))\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1, 101): #patient 1 is first \n",
    "        #reset x_train for next batch\n",
    "        if count == 0:\n",
    "            x_train = np.zeros((batch_size, height_width,height_width,z_size))  #reset the x_train array at the start of a batch\n",
    "        \n",
    "        path = OUTPUT_FOLDER + 'patient_' + str(i) + '.npy'\n",
    "        if os.path.isfile(path):\n",
    "            print(str(i))\n",
    "            image = np.load(path)\n",
    "            image = tf.image.resize_images(image, (height_width,height_width), method = tf.image.ResizeMethod.AREA).eval()\n",
    "            image = np.swapaxes(image, 1,2)\n",
    "            image = tf.image.resize_images(image, (height_width,height_width), method = tf.image.ResizeMethod.AREA).eval()\n",
    "            image = np.swapaxes(image, 1,2)\n",
    "            x_train[count] = image  #add preprocessed example to train_set\n",
    "            \n",
    "            #On the 20th example, save the mini_batch and reset variables as necessary\n",
    "            if count % 19 == 0 and count != 0:\n",
    "                print(x_train.shape)\n",
    "                np.save('./database/mini_train_x_' + str(batch_num), x_train)\n",
    "                count = 0\n",
    "                batch_num += 1\n",
    "            else:    \n",
    "                count += 1\n",
    "\n",
    "\n",
    "#Repeat the above for the test set of size 100\n",
    "batch_num = 0\n",
    "count = 0\n",
    "x_test = np.zeros((batch_size, height_width,height_width,z_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(101, 201):\n",
    "        #reset x_train for next batch\n",
    "        if count == 0:\n",
    "            x_test = np.zeros((batch_size, height_width,height_width,z_size))\n",
    "            \n",
    "        path = OUTPUT_FOLDER + 'patient_' + str(i) + '.npy'\n",
    "        if os.path.isfile(path):\n",
    "            print(str(i))\n",
    "            image = np.load(path)\n",
    "            image = tf.image.resize_images(image, (height_width,height_width), method = tf.image.ResizeMethod.AREA).eval()\n",
    "            image = padImage(image, height_width,height_width,500)\n",
    "            \n",
    "            x_test[count] = image\n",
    "            if count % 19 == 0 and count != 0:\n",
    "                print(x_test.shape)\n",
    "                np.save('./database/mini_test_x_' + str(batch_num), x_test)\n",
    "                count = 0\n",
    "                batch_num += 1\n",
    "            else:    \n",
    "                count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.load('stage_2yTrue.npy')[0:100]   #Create train set true values\n",
    "y_test = np.load('stage_2yTrue.npy')[100:200]  #Create test set true values\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "np.save('mini_y_train', y_train)   #Save the train set true values\n",
    "np.save('mini_y_test', y_test)     #Save the test set true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
